{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhhgOU2mpUPJ"
      },
      "source": [
        "Run next cell only once\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-jf6uMDahp2",
        "outputId": "ca30e162-8a66-45bc-d7f9-aa2ec6fbb3d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: newspaper3k in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (4.12.3)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (10.2.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (6.0.1)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (1.2.0)\n",
            "Requirement already satisfied: lxml>=3.6.0 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (5.1.0)\n",
            "Requirement already satisfied: nltk>=3.2.1 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (3.8.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (2.31.0)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (6.0.11)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (5.1.1)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (2.8.2)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.5)\n",
            "Requirement already satisfied: six in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
            "Requirement already satisfied: sgmllib3k in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: click in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2024.2.2)\n",
            "Requirement already satisfied: requests-file>=1.4 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (2.0.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (3.13.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk>=3.2.1->newspaper3k) (0.4.6)\n",
            "Could not fetch URL https://pypi.org/simple/pip/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pip/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)'))) - skipping\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: sumy in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.11.0)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: breadability>=0.1.20 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: requests>=2.7.0 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sumy) (2.31.0)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sumy) (23.12.11)\n",
            "Requirement already satisfied: nltk>=3.0.2 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sumy) (3.8.1)\n",
            "Requirement already satisfied: chardet in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from breadability>=0.1.20->sumy) (5.1.0)\n",
            "Requirement already satisfied: click in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.0.2->sumy) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.0.2->sumy) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.0.2->sumy) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.7.0->sumy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.7.0->sumy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.7.0->sumy) (2.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.7.0->sumy) (2024.2.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\ak04726p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk>=3.0.2->sumy) (0.4.6)\n",
            "Could not fetch URL https://pypi.org/simple/pip/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pip/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)'))) - skipping\n"
          ]
        }
      ],
      "source": [
        "%pip install newspaper3k\n",
        "%pip install sumy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnrHfuOkmLdN"
      },
      "source": [
        "Start running here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeD96dEwfwDf",
        "outputId": "db4f1427-d1bd-479b-f453-1689d76a6d6d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\AK04726P\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U3gJkEuexu7",
        "outputId": "dc0f92e4-d36f-4c6c-a73a-d8340dbb5312"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "unexpected indent (3880915978.py, line 94)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[15], line 94\u001b[1;36m\u001b[0m\n\u001b[1;33m    news_df = pd.DataFrame({\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import newspaper\n",
        "from requests.exceptions import Timeout\n",
        "from textblob import TextBlob\n",
        "\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "\n",
        "# Download the VADER lexicon\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "def summarize_text(text, max_sentences=3):\n",
        "    # Create a parser using PlaintextParser\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "    # Create an LSA summarizer\n",
        "    summarizer = LsaSummarizer()\n",
        "    # Summarize the text\n",
        "    summary = summarizer(parser.document, max_sentences)\n",
        "    # Return the summary as a string\n",
        "    return ' '.join(str(sentence) for sentence in summary)\n",
        "\n",
        "# Initialize the sentiment analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def get_sentiment(text):\n",
        "    sentiment_scores = sia.polarity_scores(text)\n",
        "    return sentiment_scores['compound']\n",
        "\n",
        "def web_scrape_clients(clients, max_number_news=5):\n",
        "    news_dfs = []\n",
        "\n",
        "    for client in clients:\n",
        "        # Remove commas and replace spaces with plus signs\n",
        "        client = client.replace(\",\", \"\").replace(\" \", \"+\")\n",
        "\n",
        "        url = f\"https://www.bing.com/news/search?q={client}+-msn\"\n",
        "        response = requests.get(url, verify=False)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "            headers = [a.text for a in soup.select(\".t_t a.title\")]\n",
        "            journals = [a[\"data-author\"] for a in soup.select(\".t_t a.title\")]\n",
        "            links = [a[\"href\"] for a in soup.select(\".t_t a.title\")]\n",
        "            snippet = [s.text for s in soup.select(\".snippet\")]\n",
        "            summary = []\n",
        "            sentiment = []\n",
        "\n",
        "            num_news = min(len(headers), max_number_news)\n",
        "\n",
        "        summary.append(\"error\")\n",
        "        sentiment.append(0)  # Assuming default sentiment value for error cases\n",
        "\n",
        "        # Update the code inside the loop where summaries and sentiments are appended\n",
        "        for link in links:\n",
        "\n",
        "            try:\n",
        "                # Use requests to download the page content with a timeout of 5 seconds\n",
        "                response = requests.get(link, timeout=20)\n",
        "                page_content = response.content\n",
        "\n",
        "                article = newspaper.Article(link)\n",
        "                article.download(input_html=page_content)\n",
        "                article.parse()\n",
        "                article.nlp()\n",
        "\n",
        "                if not article.text:\n",
        "                    sentiment.append(\"-\")\n",
        "                    summary.append(\"Could not get the summary for this article: Subscription needed.\")\n",
        "                    continue  # Skip articles with empty text\n",
        "\n",
        "                sentiment.append(get_sentiment(article.text))\n",
        "                summary.append(summarize_text(article.text))\n",
        "\n",
        "                if len(summary) == max_number_news:\n",
        "                    break  # Stop when desired number of non-empty summaries is reached\n",
        "\n",
        "            except Timeout:\n",
        "                summary.append(\"error\")\n",
        "                sentiment.append(0)  # Default sentiment for error case\n",
        "            except Exception as e:\n",
        "                summary.append(\"error\")\n",
        "                sentiment.append(0)  # Default sentiment for error case\n",
        "\n",
        "\n",
        "\n",
        "            news_df = pd.DataFrame({\n",
        "                \"Client\": [client] * num_news,\n",
        "                \"Header\": headers[:num_news],\n",
        "                \"Snippet\": snippet[:num_news],\n",
        "                \"Journal\": journals[:num_news],\n",
        "                \"Link\": links[:num_news],\n",
        "                \"Summary\" : summary[:num_news],\n",
        "                \"Sentiment\": sentiment[:num_news]\n",
        "            })\n",
        "\n",
        "            news_dfs.append(news_df)\n",
        "\n",
        "    final_news_df = pd.concat(news_dfs, ignore_index=True)\n",
        "    final_news_df[\"Client\"] = final_news_df[\"Client\"].str.replace(\"+\", \" \")\n",
        "    final_news_df[\"Link\"] = final_news_df[\"Link\"].apply(lambda x: f'<a href=\"{x}\" target=\"_blank\">{x}</a>')\n",
        "\n",
        "\n",
        "\n",
        "    return final_news_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gutX5kVUmYLD"
      },
      "source": [
        "After running the following line, it will ask you to type a client name and press enter. Once the table loads, you can click on the little table icon on the right to read the summaries better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "220NGImjcx8g",
        "outputId": "c47f5350-32a4-475f-f8b9-80d567509b75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\AK04726P\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.bing.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "All arrays must be of the same length",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m#display(final_news_df)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m#final_news_df.to_csv('news_data.csv', index=False)  # Save as CSV\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[14], line 9\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m      8\u001b[0m     clients \u001b[38;5;241m=\u001b[39m get_user_input()\n\u001b[1;32m----> 9\u001b[0m     final_news_df \u001b[38;5;241m=\u001b[39m \u001b[43mweb_scrape_clients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_number_news\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Display the DataFrame\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display, HTML\n",
            "Cell \u001b[1;32mIn[10], line 87\u001b[0m, in \u001b[0;36mweb_scrape_clients\u001b[1;34m(clients, max_number_news)\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     84\u001b[0m                 summary\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 87\u001b[0m         news_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClient\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_news\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHeader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_news\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSnippet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msnippet\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_news\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mJournal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjournals\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_news\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLink\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinks\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_news\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSummary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_news\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSentiment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msentiment\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_news\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m         news_dfs\u001b[38;5;241m.\u001b[39mappend(news_df)\n\u001b[0;32m     99\u001b[0m final_news_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(news_dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\AK04726P\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:767\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    761\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    762\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    763\u001b[0m     )\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 767\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
            "File \u001b[1;32mc:\\Users\\AK04726P\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\AK04726P\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
            "File \u001b[1;32mc:\\Users\\AK04726P\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
          ]
        }
      ],
      "source": [
        "def get_user_input():\n",
        "    clients = input(\"Enter a list of clients separated by commas: \")\n",
        "    clients = clients.split(\",\")\n",
        "    clients = [client.strip() for client in clients]\n",
        "    return clients\n",
        "\n",
        "def main():\n",
        "    clients = get_user_input()\n",
        "    final_news_df = web_scrape_clients(clients, max_number_news=5)\n",
        "\n",
        "    # Display the DataFrame\n",
        "    from IPython.display import display, HTML\n",
        "    # Display the DataFrame with clickable hyperlinks\n",
        "    display(HTML(final_news_df.to_html(escape=False)))\n",
        "    #display(final_news_df)\n",
        "    #final_news_df.to_csv('news_data.csv', index=False)  # Save as CSV\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
