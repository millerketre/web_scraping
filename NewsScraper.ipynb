{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Run next cell only once\n"
      ],
      "metadata": {
        "id": "BhhgOU2mpUPJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-jf6uMDahp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca30e162-8a66-45bc-d7f9-aa2ec6fbb3d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting newspaper3k\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.11.2)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (6.0.1)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.9.3)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (3.8.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.31.0)\n",
            "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tldextract>=2.0.1 (from newspaper3k)\n",
            "  Downloading tldextract-5.1.0-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting feedfinder2>=0.0.4 (from newspaper3k)\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.8.2)\n",
            "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
            "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2023.7.22)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.13.1)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13540 sha256=d9e3cc123843c4a983b34569797de1388d25926e12c99d6daaf204c0674691e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d6/6c/384f58df48c00b9a31d638005143b5b3ac62c3d25fb1447f23\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3339 sha256=c7dd08193fbb02628feb1df9844b3af440b686ec6f56b42134d892e25e41b2be\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/02/e7/a1ff1760e12bdbaab0ac824fae5c1bc933e41c4ccd6a8f8edb\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398381 sha256=28848fd9a2018115053755b7a7ca28888115d2e655c727e57cebc225f8701dde\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/c4/0c/12a9a314ecac499456c4c3b2fcc2f635a3b45a39dfbd240299\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6049 sha256=da15967dd459a979cd519d2ad83a347221078c2da8e7c04274e20862f32e87a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, cssselect, requests-file, feedfinder2, tldextract, newspaper3k\n",
            "Successfully installed cssselect-1.2.0 feedfinder2-0.0.4 feedparser-6.0.10 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-5.1.0\n",
            "Collecting sumy\n",
            "  Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt<0.7,>=0.6.1 (from sumy)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting breadability>=0.1.20 (from sumy)\n",
            "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from sumy) (2.31.0)\n",
            "Collecting pycountry>=18.2.23 (from sumy)\n",
            "  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from sumy) (3.8.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.9.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (4.66.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pycountry>=18.2.23->sumy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2023.7.22)\n",
            "Building wheels for collected packages: breadability, docopt, pycountry\n",
            "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21692 sha256=ce48adaf86dc723da7e6b8a7f6d8eddba385112d90979d4fe1fb8ca307db40e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/22/90/b84fcc30e16598db20a0d41340616dbf9b1e82bbcc627b0b33\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=47fb7840811742a1f059522ed826f0dae25ecad9b0d74bbab84c5c533eb99816\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for pycountry (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681832 sha256=248dc2fb03e7102d7ef2177b103a32557df68ebe8d3d45f917e51c30cebd2f2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/57/cc/290c5252ec97a6d78d36479a3c5e5ecc76318afcb241ad9dbe\n",
            "Successfully built breadability docopt pycountry\n",
            "Installing collected packages: docopt, pycountry, breadability, sumy\n",
            "Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-22.3.5 sumy-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install newspaper3k\n",
        "!pip install sumy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start running here"
      ],
      "metadata": {
        "id": "JnrHfuOkmLdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeD96dEwfwDf",
        "outputId": "db4f1427-d1bd-479b-f453-1689d76a6d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import newspaper\n",
        "from requests.exceptions import Timeout\n",
        "from textblob import TextBlob\n",
        "\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "\n",
        "# Download the VADER lexicon\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "def summarize_text(text, max_sentences=3):\n",
        "    # Create a parser using PlaintextParser\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "    # Create an LSA summarizer\n",
        "    summarizer = LsaSummarizer()\n",
        "    # Summarize the text\n",
        "    summary = summarizer(parser.document, max_sentences)\n",
        "    # Return the summary as a string\n",
        "    return ' '.join(str(sentence) for sentence in summary)\n",
        "\n",
        "# Initialize the sentiment analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def get_sentiment(text):\n",
        "    sentiment_scores = sia.polarity_scores(text)\n",
        "    return sentiment_scores['compound']\n",
        "\n",
        "def web_scrape_clients(clients, max_number_news=5):\n",
        "    news_dfs = []\n",
        "\n",
        "    for client in clients:\n",
        "        # Remove commas and replace spaces with plus signs\n",
        "        client = client.replace(\",\", \"\").replace(\" \", \"+\")\n",
        "\n",
        "        url = f\"https://www.bing.com/news/search?q={client}+-msn\"\n",
        "        response = requests.get(url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "            headers = [a.text for a in soup.select(\".t_t a.title\")]\n",
        "            journals = [a[\"data-author\"] for a in soup.select(\".t_t a.title\")]\n",
        "            links = [a[\"href\"] for a in soup.select(\".t_t a.title\")]\n",
        "            snippet = [s.text for s in soup.select(\".snippet\")]\n",
        "            summary = []\n",
        "            sentiment = []\n",
        "\n",
        "            num_news = min(len(headers), max_number_news)\n",
        "\n",
        "            for link in links:\n",
        "\n",
        "                try:\n",
        "                    # Use requests to download the page content with a timeout of 5 seconds\n",
        "                    response = requests.get(link, timeout=20)\n",
        "                    page_content = response.content\n",
        "\n",
        "                    article = newspaper.Article(link)\n",
        "                    article.download(input_html=page_content)\n",
        "                    article.parse()\n",
        "                    article.nlp()\n",
        "\n",
        "                    if not article.text:\n",
        "                        sentiment.append(\"-\")\n",
        "                        summary.append(\"Could not get the summary for this article: Subscription needed.\")\n",
        "                        continue  # Skip articles with empty text\n",
        "\n",
        "                    sentiment.append(get_sentiment(article.text))\n",
        "                    summary.append(summarize_text(article.text))\n",
        "\n",
        "                    if len(summary) == max_number_news:\n",
        "                        break  # Stop when desired number of non-empty summaries is reached\n",
        "\n",
        "                except Timeout:\n",
        "                    summary.append(\"error\")\n",
        "                except Exception as e:\n",
        "                    summary.append(\"error\")\n",
        "\n",
        "\n",
        "            news_df = pd.DataFrame({\n",
        "                \"Client\": [client] * num_news,\n",
        "                \"Header\": headers[:num_news],\n",
        "                \"Snippet\": snippet[:num_news],\n",
        "                \"Journal\": journals[:num_news],\n",
        "                \"Link\": links[:num_news],\n",
        "                \"Summary\" : summary[:num_news],\n",
        "                \"Sentiment\": sentiment[:num_news]\n",
        "            })\n",
        "\n",
        "            news_dfs.append(news_df)\n",
        "\n",
        "    final_news_df = pd.concat(news_dfs, ignore_index=True)\n",
        "    final_news_df[\"Client\"] = final_news_df[\"Client\"].str.replace(\"+\", \" \")\n",
        "    final_news_df[\"Link\"] = final_news_df[\"Link\"].apply(lambda x: f'<a href=\"{x}\" target=\"_blank\">{x}</a>')\n",
        "\n",
        "\n",
        "\n",
        "    return final_news_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U3gJkEuexu7",
        "outputId": "dc0f92e4-d36f-4c6c-a73a-d8340dbb5312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running the following line, it will ask you to type a client name and press enter. Once the table loads, you can click on the little table icon on the right to read the summaries better"
      ],
      "metadata": {
        "id": "gutX5kVUmYLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_input():\n",
        "    clients = input(\"Enter a list of clients separated by commas: \")\n",
        "    clients = clients.split(\",\")\n",
        "    clients = [client.strip() for client in clients]\n",
        "    return clients\n",
        "\n",
        "def main():\n",
        "    clients = get_user_input()\n",
        "    final_news_df = web_scrape_clients(clients, max_number_news=5)\n",
        "\n",
        "    # Display the DataFrame\n",
        "    from IPython.display import display, HTML\n",
        "    # Display the DataFrame with clickable hyperlinks\n",
        "    display(HTML(final_news_df.to_html(escape=False)))\n",
        "    #display(final_news_df)\n",
        "    #final_news_df.to_csv('news_data.csv', index=False)  # Save as CSV\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "220NGImjcx8g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c47f5350-32a4-475f-f8b9-80d567509b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a list of clients separated by commas: Hiscox, Beazley\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-7f3e4b171efd>:100: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  final_news_df[\"Client\"] = final_news_df[\"Client\"].str.replace(\"+\", \" \")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Client</th>\n",
              "      <th>Header</th>\n",
              "      <th>Snippet</th>\n",
              "      <th>Journal</th>\n",
              "      <th>Link</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hiscox</td>\n",
              "      <td>Hiscox Ltd (LON:HSX) is a favorite amongst institutional investors who own 72%</td>\n",
              "      <td>If you want to know who really controls Hiscox Ltd ( LON:HSX ), then you'll have to look at the makeup of its share registry.</td>\n",
              "      <td>YAHOO!Finance</td>\n",
              "      <td><a href=\"https://finance.yahoo.com/news/hiscox-ltd-lon-hsx-favorite-093008386.html\" target=\"_blank\">https://finance.yahoo.com/news/hiscox-ltd-lon-hsx-favorite-093008386.html</a></td>\n",
              "      <td>Institutional investors own over 50% of the company, so together than can probably strongly influence board decisions. We've identified 1 warning sign with Hiscox , and understanding them should be part of your investment process. If you would prefer discover what analysts are predicting in terms of future growth, do not miss this free report on analyst forecasts.</td>\n",
              "      <td>0.9959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hiscox</td>\n",
              "      <td>Hiscox Ltd: Syndicates 33 and 6104 – results and estimates</td>\n",
              "      <td>Syndicates 33 and 6104 - results and estimates Hamilton, Bermuda (10 November 2023) - Hiscox Ltd (LSE: HSX), the ...</td>\n",
              "      <td>Cbonds</td>\n",
              "      <td><a href=\"https://cbonds.com/news/2578985/\" target=\"_blank\">https://cbonds.com/news/2578985/</a></td>\n",
              "      <td>Full data on over 800,000 bonds and stocks worldwide Powerful bond screener Ratings from the top 3 global ratings agencies, plus over 70 local ones</td>\n",
              "      <td>0.5574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hiscox</td>\n",
              "      <td>Hiscox Ltd HSX</td>\n",
              "      <td>Morningstar Quantitative Ratings for Stocks are generated using an algorithm that compares companies that are not under analyst coverage to peer companies that do receive analyst-driven ratings ...</td>\n",
              "      <td>Morningstar</td>\n",
              "      <td><a href=\"https://www.morningstar.com/stocks/xlon/hsx/quote\" target=\"_blank\">https://www.morningstar.com/stocks/xlon/hsx/quote</a></td>\n",
              "      <td>Companies with quantitative ratings are not formally covered by a Morningstar analyst, but are statistically matched to analyst-rated companies, allowing our models to calculate a quantitative moat, fair value, and uncertainty rating. Is it the right time to buy, sell, or hold? Start a free trial of Morningstar Investor to unlock exclusive ratings and continuous analyst coverage to help you decide if HSX is a good fit for your portfolio.</td>\n",
              "      <td>0.9628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hiscox</td>\n",
              "      <td>Hiscox reports cyber-attacks continue to rise year-on-year</td>\n",
              "      <td>UK insurer, Hiscox has released its seventh annual Cyber Readiness Report. The key finding from the report was that 53% of ...</td>\n",
              "      <td>enterprisetimes.co.uk</td>\n",
              "      <td><a href=\"https://www.enterprisetimes.co.uk/2023/11/02/hiscox-reports-cyber-attacks-continue-to-rise-year-on-year/\" target=\"_blank\">https://www.enterprisetimes.co.uk/2023/11/02/hiscox-reports-cyber-attacks-continue-to-rise-year-on-year/</a></td>\n",
              "      <td>This website is using a security service to protect itself from online attacks. There are several actions that could trigger this block including submitting a certain word or phrase, a SQL command or malformed data. Please include what you were doing when this page came up and the Cloudflare Ray ID found at the bottom of this page.</td>\n",
              "      <td>0.7450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hiscox</td>\n",
              "      <td>Hiscox reports strong written premium growth</td>\n",
              "      <td>Specialist insurer Hiscox reported strong growth in group insurance contract written premiums (ICWP) on Wednesday in the ...</td>\n",
              "      <td>Sharecast</td>\n",
              "      <td><a href=\"https://www.sharecast.com/news/news-and-announcements/hiscox-reports-strong-written-premium-growth--15248966.html\" target=\"_blank\">https://www.sharecast.com/news/news-and-announcements/hiscox-reports-strong-written-premium-growth--15248966.html</a></td>\n",
              "      <td>The London Market segment of Hiscox saw net ICWP increase by an impressive 18.1% to reach $676.7m. Furthermore, Hiscox ILS funds delivered record performance, generating an increasing fee income for the group. Despite an active third quarter, aggregate natural catastrophe losses year-to-date remained within budget.</td>\n",
              "      <td>0.9985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Beazley</td>\n",
              "      <td>Beazley cyber cat bond hits the market, $75m PoleStar Re Ltd.</td>\n",
              "      <td>Beazley, the London headquartered specialty insurance and reinsurance underwriter, has now entered the 144A catastrophe bond ...</td>\n",
              "      <td>Artemis</td>\n",
              "      <td><a href=\"https://www.artemis.bm/news/beazley-cyber-cat-bond-hits-the-market-75m-polestar-re-ltd/\" target=\"_blank\">https://www.artemis.bm/news/beazley-cyber-cat-bond-hits-the-market-75m-polestar-re-ltd/</a></td>\n",
              "      <td>Beazley had already sponsored three private cyber catastrophe bonds so far this year, but we were told that a renewal of the coverage would likely come in full 144a cat bond form, and this new PoleStar Re cyber cat bond appears to be that deal. With the AXIS Capital deal progressing and expected to be priced in the next day or so, this sends a strong signal that insurance-linked securities (ILS) investors are welcoming this new peril and ready to assess it, investing in it where appropriate for their portfolios. In addition, Gallagher Securities is structuring and offering this deal, so that’s a second broker involved as well (Aon is working on the AXIS deal), again very positive for the cyber cat bond market’s growth potential</td>\n",
              "      <td>0.0457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Beazley</td>\n",
              "      <td>Beazley: Holding(s) in Company</td>\n",
              "      <td>TR-1: Standard form for notification of major holdings 1. Issuer Details ISIN GB00BYQ0JC66 Issuer Name BEAZLEY PLC UK or Non-UK Issuer UK 2. Reason for Notification An acquisition or disposal of ...</td>\n",
              "      <td>Cbonds</td>\n",
              "      <td><a href=\"https://cbonds.com/news/2573855/\" target=\"_blank\">https://cbonds.com/news/2573855/</a></td>\n",
              "      <td>Full data on over 800,000 bonds and stocks worldwide Powerful bond screener Ratings from the top 3 global ratings agencies, plus over 70 local ones</td>\n",
              "      <td>0.5574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Beazley</td>\n",
              "      <td>Beazley publishes Q3 financials</td>\n",
              "      <td>Beazley has unveiled its financials for the nine-month period ending Sept. 30. The specialist insurance group underscored robust financial performance with insurance written premiums climbing by 9% to ...</td>\n",
              "      <td>insurancebusinessmag</td>\n",
              "      <td><a href=\"https://www.insurancebusinessmag.com/asia/news/breaking-news/beazley-publishes-q3-financials-465876.aspx\" target=\"_blank\">https://www.insurancebusinessmag.com/asia/news/breaking-news/beazley-publishes-q3-financials-465876.aspx</a></td>\n",
              "      <td>In the cyber risk segment, despite a moderate rate decrease in 2023, the current pricing levels are considered sufficient, particularly against the backdrop of the significant rate rises that have occurred since 2019. While the US mid-market shows promise for growth, competition has intensified, particularly in the SME space, leading to a more moderate growth rate in the US. However, the company has seen substantial growth in other regions where market penetration rates are lower.</td>\n",
              "      <td>0.8126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Beazley</td>\n",
              "      <td>Beazley takes advantage of “exceptional” property market in 9M 2023</td>\n",
              "      <td>Specialist insurer Beazley has reported insurance written premium growth of 9% to $4.3 billion for the first nine months of ...</td>\n",
              "      <td>reinsurancene</td>\n",
              "      <td><a href=\"https://www.reinsurancene.ws/beazley-takes-advantage-of-exceptional-property-market-in-9m-2023/\" target=\"_blank\">https://www.reinsurancene.ws/beazley-takes-advantage-of-exceptional-property-market-in-9m-2023/</a></td>\n",
              "      <td>In Cyber Risks, premiums rose 4% to $872 million, although there’s been a moderate rate decrease during 2023. Natural catastrophe losses have so far been within the margins held in its reserves for such events. “With sustained discipline and agility in our underwriting I look forward to reporting a strong profit at year end.”</td>\n",
              "      <td>0.9873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Beazley</td>\n",
              "      <td>Beazley flags strong year after solid third quarter</td>\n",
              "      <td>Specialist insurer Beazley announced a positive trading performance for the first nine months of 2023 on Tuesday, with a 9% ...</td>\n",
              "      <td>Sharecast</td>\n",
              "      <td><a href=\"https://www.sharecast.com/news/market-pulse/beazley-flags-strong-year-after-solid-third-quarter--15229850.html\" target=\"_blank\">https://www.sharecast.com/news/market-pulse/beazley-flags-strong-year-after-solid-third-quarter--15229850.html</a></td>\n",
              "      <td>It also saw growth in its cyber, marine, political risks and contingency lines of business. Cox described the insurance business as cyclical, adding that market conditions were rapidly evolving. “With sustained discipline and agility in our underwriting, I look forward to reporting a strong profit at year-end.”</td>\n",
              "      <td>0.9926</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}